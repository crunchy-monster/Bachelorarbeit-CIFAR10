{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4789e282-9bba-49c2-ba17-5be04772ba5e",
   "metadata": {},
   "source": [
    "# CNN for CIFAR-10 dataset and LeNet-5 architectur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e258f-e2ab-41fd-bba2-d21e60d04c6f",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24a6de2-8186-4c30-8643-63e07be01171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load and normalize CIFAR10\n",
    "# https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad45e9-7938-4e14-b422-40f0c269342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "batch_size = 4\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Loading the dataset and preprocessing\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,0.5,0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589558d-83a5-40ad-9b18-893b09cee66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der ersten Bilder des Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779fde38-0219-43f4-9449-af7c16253cb6",
   "metadata": {},
   "source": [
    "### Building the CNN\n",
    "\n",
    "https://medium.com/@myringoleMLGOD/simple-convolutional-neural-network-cnn-for-dummies-in-pytorch-a-step-by-step-guide-6f4109f6df80\n",
    "\n",
    "https://github.com/lychengrex/LeNet-5-Implementation-Using-Pytorch/blob/master/LeNet-5%20Implementation%20Using%20Pytorch.ipynb\n",
    "\n",
    "Code: https://www.digitalocean.com/community/tutorials/writing-lenet5-from-scratch-in-python <br>\n",
    "https://www.youtube.com/watch?v=fcOW-Zyb5Bo\n",
    "\n",
    "orig. paper: http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf\n",
    "\n",
    "Faltungsneuronale Netze von Grund auf\n",
    "https://www.youtube.com/watch?v=jDe5BAsT2-Y\n",
    "\n",
    "LeNet-5 explained: https://www.youtube.com/watch?v=lEBFpI7bqw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "536b5d1a-47b8-4f25-8bcf-eb1b27ad50a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# LeNet architecture\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 1x32x32 Input <- (5x5), s=1, p=0 -> avg pool s=2, p=0 -> (5x5), s=1,p=0 -> avg pool s=2 P=0\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# -> Conv 5x5 to 120 channels x Linear 84 x Linear 10\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#Defining the convolutional neural network\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLeNet5\u001b[39;00m(\u001b[43mnn\u001b[49m.Module):\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes):\n\u001b[32m     10\u001b[39m         \u001b[38;5;28msuper\u001b[39m(ConvNeuralNet, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# LeNet architecture\n",
    "# 1x32x32 Input <- (5x5), s=1, p=0 -> avg pool s=2, p=0 -> (5x5), s=1,p=0 -> avg pool s=2 P=0\n",
    "# -> Conv 5x5 to 120 channels x Linear 84 x Linear 10\n",
    "\n",
    "# Defining the cnn\n",
    "\n",
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "        nn.BatchNorm2d(6),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Before training hyperparameters neet to be set\n",
    "\n",
    "model = LeNet5(num_classes).to(device)\n",
    "    \n",
    "#Setting the loss function\n",
    "cost = nn.CrossEntropyLoss()\n",
    "    \n",
    "#Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "#this is defined to print how many steps are remaining when training\n",
    "total_step = len(train_loader)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "            \n",
    "        #Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 400 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "\n",
    "        # Test the model\n",
    "# In the test phase, we don't need to compute gradients (for memory efficiency)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e3f97-0ec8-4fb2-a4bc-6428d90dc2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=fcOW-Zyb5Bo\n",
    "# https://github.com/AbXD8901/Comparison-of-CNN-Architectures-on-Different-Datasets/blob/main/LeNet-5.py\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AvgPool2d(kernel_size(2,2), stride(2,2))\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5,5), stride=(1,1), padding=(0,0))\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5), stride=(1,1), padding=(0,0))\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5,5), stride=(1,1), padding=(0,0))\n",
    "        self.linear1 = nn.Linear(120, 84)\n",
    "        self.linear2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))  # number_expamples x 120 x 1 x 1 --> num_examples x 120\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bachelorarbeit)",
   "language": "python",
   "name": "bachelorarbeit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
