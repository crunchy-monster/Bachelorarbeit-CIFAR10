
BATCH_SIZE = 8  # Anzahl der Trainingsbeispiele pro Gradienten-Update.
LR = 1e-3  # (Learning Rate) - standartwert für Adam - Schrittweite der Gewichtsaktualisierung.
EPOCHS = 10 # Wie oft das Modell den gesamten Trainingsdatensatz sieht.
WEIGHT_DECAY = 0.0 # L2-Regularisierung (bestraft große Gewichte). 0.0 keine Regularisierung
SEED = 42 # Setzt den Zufallsstartpunkt: